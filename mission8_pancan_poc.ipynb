{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62bc7c9a",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8611cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Disable TensorFlow GPU BEFORE importing TF (RTX 5070 sm_120 not yet supported)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# Add src to path\n",
    "sys.path.insert(0, os.path.abspath('.'))\n",
    "\n",
    "# Data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Deep Learning - PyTorch (uses GPU)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Deep Learning - TensorFlow (for VGG16 baseline)\n",
    "import tensorflow as tf\n",
    "# Force TF to CPU using soft placement\n",
    "with tf.device('/CPU:0'):\n",
    "    pass  # TF will run VGG16 on CPU\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Reload modules to pick up changes\n",
    "import importlib\n",
    "import src.classes.pancan_classifier\n",
    "importlib.reload(src.classes.pancan_classifier)\n",
    "\n",
    "# Custom modules\n",
    "from src.classes.data_loader import FlipkartDataLoader, ImageDataset\n",
    "from src.classes.pancan_classifier import PanCANClassifier, create_pancan_model\n",
    "from src.classes.vgg16_baseline import VGG16Classifier\n",
    "from src.classes.metrics_evaluator import MetricsEvaluator\n",
    "from src.classes.model_comparison import ModelComparison\n",
    "from src.classes.context_aggregation import FeatureImportanceAnalyzer\n",
    "\n",
    "# Set device for PyTorch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"PyTorch device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "print(f\"TensorFlow: Will use CPU with soft device placement\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3834b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "CONFIG = {\n",
    "    # Paths\n",
    "    'dataset_path': Path('./dataset/Flipkart'),\n",
    "    'models_path': Path('./models'),\n",
    "    'reports_path': Path('./reports'),\n",
    "    \n",
    "    # Data\n",
    "    'image_size': 224,\n",
    "    'batch_size': 16,\n",
    "    'test_size': 0.25,\n",
    "    'val_size': 0.15,\n",
    "    \n",
    "    # Training\n",
    "    'epochs': 20,\n",
    "    'learning_rate': 1e-4,\n",
    "    'weight_decay': 0.01,\n",
    "    'patience': 5,\n",
    "    \n",
    "    # PanCAN specific\n",
    "    'num_walk_orders': 3,\n",
    "    'hidden_dim': 512,\n",
    "    'dropout': 0.3,\n",
    "    \n",
    "    # Random seed\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "np.random.seed(CONFIG['seed'])\n",
    "torch.manual_seed(CONFIG['seed'])\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(CONFIG['seed'])\n",
    "tf.random.set_seed(CONFIG['seed'])\n",
    "\n",
    "print(\"Configuration loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543b1c9a",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1574ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data loader\n",
    "data_loader = FlipkartDataLoader(\n",
    "    dataset_path=CONFIG['dataset_path'],\n",
    "    random_seed=CONFIG['seed']\n",
    ")\n",
    "\n",
    "# Load data\n",
    "df = data_loader.load_data()\n",
    "print(f\"\\nDataset shape: {df.shape}\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d79cef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract categories and encode labels\n",
    "categories = data_loader.extract_categories(level=0)\n",
    "\n",
    "# Validate images\n",
    "df = data_loader.validate_images()\n",
    "\n",
    "# Get class information\n",
    "class_names = data_loader.class_names\n",
    "num_classes = data_loader.num_classes\n",
    "\n",
    "print(f\"\\nClasses ({num_classes}): {class_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26a425d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display class distribution\n",
    "class_dist = data_loader.get_class_distribution()\n",
    "print(\"\\nClass Distribution:\")\n",
    "print(class_dist)\n",
    "\n",
    "# Visualize\n",
    "fig = px.bar(\n",
    "    x=class_dist.index,\n",
    "    y=class_dist.values,\n",
    "    title='Class Distribution in Flipkart Dataset',\n",
    "    labels={'x': 'Category', 'y': 'Count'},\n",
    "    color=class_dist.values,\n",
    "    color_continuous_scale='Viridis'\n",
    ")\n",
    "fig.update_layout(showlegend=False, xaxis_tickangle=-45)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209385e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "train_df, val_df, test_df = data_loader.split_data(\n",
    "    test_size=CONFIG['test_size'],\n",
    "    val_size=CONFIG['val_size']\n",
    ")\n",
    "\n",
    "print(f\"\\nTrain samples: {len(train_df)}\")\n",
    "print(f\"Validation samples: {len(val_df)}\")\n",
    "print(f\"Test samples: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5643f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transforms for PyTorch (PanCAN)\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((CONFIG['image_size'], CONFIG['image_size'])),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((CONFIG['image_size'], CONFIG['image_size'])),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "print(\"Transforms defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe43fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PyTorch datasets\n",
    "train_dataset = ImageDataset(train_df, transform=train_transform)\n",
    "val_dataset = ImageDataset(val_df, transform=val_transform)\n",
    "test_dataset = ImageDataset(test_df, transform=val_transform)\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=True if torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Validation batches: {len(val_loader)}\")\n",
    "print(f\"Test batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649d2f7b",
   "metadata": {},
   "source": [
    "## 3. Model Initialization\n",
    "\n",
    "### 3.1 PanCAN with ResNet101 Backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662a844f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RTX 5070 (sm_120/Blackwell) - Use torch.compile() to JIT compile CUDA kernels\n",
    "import os\n",
    "os.environ['TORCH_LOGS'] = 'recompiles'  # Show compilation info\n",
    "\n",
    "device = torch.device('cuda')\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "# Create models and compile them with Inductor/Triton backend\n",
    "print(\"\\nCreating PanCAN-ResNet101 with torch.compile()...\")\n",
    "pancan_resnet101 = create_pancan_model(\n",
    "    backbone='resnet101',\n",
    "    num_classes=num_classes,\n",
    "    pretrained=True,\n",
    "    num_walk_orders=3\n",
    ").to(device)\n",
    "\n",
    "# Compile with inductor backend (uses Triton for JIT kernel compilation)\n",
    "pancan_resnet101 = torch.compile(pancan_resnet101, mode='reduce-overhead')\n",
    "\n",
    "# Warm-up forward pass to trigger JIT compilation\n",
    "print(\"Compiling kernels (first forward pass)...\")\n",
    "with torch.no_grad():\n",
    "    dummy = torch.randn(2, 3, 224, 224, device=device)\n",
    "    _ = pancan_resnet101(dummy)\n",
    "print(\"✓ PanCAN-ResNet101 compiled successfully!\")\n",
    "\n",
    "total_params = sum(p.numel() for p in pancan_resnet101.parameters())\n",
    "print(f\"PanCAN-ResNet101: {total_params:,} params on CUDA\")\n",
    "\n",
    "# Create and compile PanCAN-ConvNeXt\n",
    "print(\"\\nCreating PanCAN-ConvNeXt with torch.compile()...\")\n",
    "pancan_convnext = create_pancan_model(\n",
    "    backbone='convnext_tiny',\n",
    "    num_classes=num_classes,\n",
    "    pretrained=True,\n",
    "    num_walk_orders=3\n",
    ").to(device)\n",
    "\n",
    "pancan_convnext = torch.compile(pancan_convnext, mode='reduce-overhead')\n",
    "\n",
    "print(\"Compiling kernels (first forward pass)...\")\n",
    "with torch.no_grad():\n",
    "    _ = pancan_convnext(dummy)\n",
    "print(\"✓ PanCAN-ConvNeXt compiled successfully!\")\n",
    "\n",
    "total_params_cvt = sum(p.numel() for p in pancan_convnext.parameters())\n",
    "print(f\"PanCAN-ConvNeXt: {total_params_cvt:,} params on CUDA\")\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"✓ PanCAN models: CUDA (torch.compile)\")\n",
    "print(f\"✓ VGG16: CPU (TensorFlow)\")\n",
    "print(f\"{'='*50}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef96368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PanCAN model with ResNet101\n",
    "pancan_resnet101 = create_pancan_model(\n",
    "    num_classes=num_classes,\n",
    "    backbone='resnet101',\n",
    "    pretrained=True,\n",
    "    num_walk_orders=CONFIG['num_walk_orders'],\n",
    "    hidden_dim=CONFIG['hidden_dim'],\n",
    "    dropout=CONFIG['dropout']\n",
    ")\n",
    "pancan_resnet101 = pancan_resnet101.to(device)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in pancan_resnet101.parameters())\n",
    "trainable_params = sum(p.numel() for p in pancan_resnet101.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"\\nPanCAN-ResNet101:\")\n",
    "print(f\"  Total parameters: {total_params:,}\")\n",
    "print(f\"  Trainable parameters: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9288cba",
   "metadata": {},
   "source": [
    "### 3.2 PanCAN with ConvNeXt-Tiny Backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bea815f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PanCAN model with ConvNeXt-Tiny\n",
    "pancan_convnext = create_pancan_model(\n",
    "    num_classes=num_classes,\n",
    "    backbone='convnext_tiny',\n",
    "    pretrained=True,\n",
    "    num_walk_orders=CONFIG['num_walk_orders'],\n",
    "    hidden_dim=CONFIG['hidden_dim'],\n",
    "    dropout=CONFIG['dropout']\n",
    ")\n",
    "pancan_convnext = pancan_convnext.to(device)\n",
    "\n",
    "# Count parameters\n",
    "total_params_cvt = sum(p.numel() for p in pancan_convnext.parameters())\n",
    "trainable_params_cvt = sum(p.numel() for p in pancan_convnext.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"\\nPanCAN-ConvNeXt-Tiny:\")\n",
    "print(f\"  Total parameters: {total_params_cvt:,}\")\n",
    "print(f\"  Trainable parameters: {trainable_params_cvt:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6769f4",
   "metadata": {},
   "source": [
    "### 3.3 VGG16 Baseline (Mission 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0967166b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create VGG16 baseline model (force CPU to avoid RTX 5070 compatibility issues)\n",
    "with tf.device('/CPU:0'):\n",
    "    vgg16_model = VGG16Classifier(\n",
    "        num_classes=num_classes,\n",
    "        class_names=class_names,\n",
    "        image_size=CONFIG['image_size'],\n",
    "        trainable_layers=0  # Frozen backbone\n",
    "    )\n",
    "\n",
    "print(f\"\\nVGG16 Baseline (CPU):\")\n",
    "vgg16_model.model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b49ab6",
   "metadata": {},
   "source": [
    "## 4. Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473c68b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_pancan_epoch(model, train_loader, optimizer, criterion, device):\n",
    "    \"\"\"Train PanCAN model for one epoch.\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch in train_loader:\n",
    "        images = batch['pixel_values'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    return total_loss / len(train_loader), correct / total\n",
    "\n",
    "\n",
    "def validate_pancan(model, val_loader, criterion, device):\n",
    "    \"\"\"Validate PanCAN model.\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            images = batch['pixel_values'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    return total_loss / len(val_loader), correct / total, all_preds, all_labels\n",
    "\n",
    "\n",
    "print(\"Training functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46373ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_pancan_model(model, train_loader, val_loader, config, device, model_name='pancan'):\n",
    "    \"\"\"Full training loop for PanCAN model.\"\"\"\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=config['learning_rate'],\n",
    "        weight_decay=config['weight_decay']\n",
    "    )\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "        optimizer, T_0=5, T_mult=2\n",
    "    )\n",
    "    \n",
    "    history = {\n",
    "        'train_loss': [], 'train_acc': [],\n",
    "        'val_loss': [], 'val_acc': []\n",
    "    }\n",
    "    \n",
    "    best_val_acc = 0\n",
    "    patience_counter = 0\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training {model_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    for epoch in range(config['epochs']):\n",
    "        # Train\n",
    "        train_loss, train_acc = train_pancan_epoch(\n",
    "            model, train_loader, optimizer, criterion, device\n",
    "        )\n",
    "        \n",
    "        # Validate\n",
    "        val_loss, val_acc, _, _ = validate_pancan(\n",
    "            model, val_loader, criterion, device\n",
    "        )\n",
    "        \n",
    "        # Update scheduler\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Save history\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        \n",
    "        # Print progress\n",
    "        print(f\"Epoch {epoch+1}/{config['epochs']} | \"\n",
    "              f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | \"\n",
    "              f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "        \n",
    "        # Early stopping\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            patience_counter = 0\n",
    "            # Save best model\n",
    "            torch.save(model.state_dict(), config['models_path'] / f'{model_name}_best.pt')\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= config['patience']:\n",
    "                print(f\"\\nEarly stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "    \n",
    "    print(f\"\\nBest validation accuracy: {best_val_acc:.4f}\")\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163a9755",
   "metadata": {},
   "source": [
    "## 5. Train Models\n",
    "\n",
    "### 5.1 Train PanCAN-ResNet101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3966dac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train PanCAN with ResNet101\n",
    "history_resnet101 = train_pancan_model(\n",
    "    pancan_resnet101,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    CONFIG,\n",
    "    device,\n",
    "    model_name='pancan_resnet101'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcc44d4",
   "metadata": {},
   "source": [
    "### 5.2 Train PanCAN-ConvNeXt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bf9891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train PanCAN with ConvNeXt-Tiny\n",
    "history_convnext = train_pancan_model(\n",
    "    pancan_convnext,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    CONFIG,\n",
    "    device,\n",
    "    model_name='pancan_convnext'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab03a06",
   "metadata": {},
   "source": [
    "### 5.3 Train VGG16 Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7770b944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data generators for VGG16 (TensorFlow)\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=15,\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=0.1,\n",
    "    brightness_range=[0.8, 1.2]\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Create generators from dataframes\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    train_df,\n",
    "    x_col='image_path',\n",
    "    y_col='main_category',\n",
    "    target_size=(CONFIG['image_size'], CONFIG['image_size']),\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    class_mode='sparse'\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_dataframe(\n",
    "    val_df,\n",
    "    x_col='image_path',\n",
    "    y_col='main_category',\n",
    "    target_size=(CONFIG['image_size'], CONFIG['image_size']),\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    class_mode='sparse'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb12850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile VGG16\n",
    "vgg16_model.compile(\n",
    "    optimizer='adam',\n",
    "    learning_rate=CONFIG['learning_rate']\n",
    ")\n",
    "\n",
    "# Train VGG16\n",
    "history_vgg16 = vgg16_model.train(\n",
    "    train_generator,\n",
    "    val_generator,\n",
    "    epochs=CONFIG['epochs'],\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=CONFIG['patience'],\n",
    "            restore_best_weights=True\n",
    "        ),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=3\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e522852",
   "metadata": {},
   "source": [
    "## 6. Evaluation and Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040d0626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize metrics evaluator\n",
    "evaluator = MetricsEvaluator(class_names=class_names)\n",
    "\n",
    "# Dictionary to store results\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5416dd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate PanCAN-ResNet101\n",
    "pancan_resnet101.load_state_dict(\n",
    "    torch.load(CONFIG['models_path'] / 'pancan_resnet101_best.pt')\n",
    ")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "_, test_acc_r101, preds_r101, labels_r101 = validate_pancan(\n",
    "    pancan_resnet101, test_loader, criterion, device\n",
    ")\n",
    "\n",
    "results['PanCAN-ResNet101'] = evaluator.compute_all_metrics(\n",
    "    np.array(labels_r101), np.array(preds_r101)\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PanCAN-ResNet101 Results\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Test Accuracy: {results['PanCAN-ResNet101']['accuracy']:.4f}\")\n",
    "print(f\"Macro F1: {results['PanCAN-ResNet101']['macro_f1']:.4f}\")\n",
    "print(f\"Weighted F1: {results['PanCAN-ResNet101']['weighted_f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52b160c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate PanCAN-ConvNeXt\n",
    "pancan_convnext.load_state_dict(\n",
    "    torch.load(CONFIG['models_path'] / 'pancan_convnext_best.pt')\n",
    ")\n",
    "\n",
    "_, test_acc_cvt, preds_cvt, labels_cvt = validate_pancan(\n",
    "    pancan_convnext, test_loader, criterion, device\n",
    ")\n",
    "\n",
    "results['PanCAN-ConvNeXt'] = evaluator.compute_all_metrics(\n",
    "    np.array(labels_cvt), np.array(preds_cvt)\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PanCAN-ConvNeXt Results\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Test Accuracy: {results['PanCAN-ConvNeXt']['accuracy']:.4f}\")\n",
    "print(f\"Macro F1: {results['PanCAN-ConvNeXt']['macro_f1']:.4f}\")\n",
    "print(f\"Weighted F1: {results['PanCAN-ConvNeXt']['weighted_f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abb9788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate VGG16\n",
    "test_generator = val_datagen.flow_from_dataframe(\n",
    "    test_df,\n",
    "    x_col='image_path',\n",
    "    y_col='main_category',\n",
    "    target_size=(CONFIG['image_size'], CONFIG['image_size']),\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    class_mode='sparse',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Get predictions\n",
    "preds_vgg16_prob = vgg16_model.model.predict(test_generator)\n",
    "preds_vgg16 = np.argmax(preds_vgg16_prob, axis=1)\n",
    "labels_vgg16 = test_generator.classes\n",
    "\n",
    "results['VGG16'] = evaluator.compute_all_metrics(\n",
    "    labels_vgg16, preds_vgg16, preds_vgg16_prob\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"VGG16 Baseline Results\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Test Accuracy: {results['VGG16']['accuracy']:.4f}\")\n",
    "print(f\"Macro F1: {results['VGG16']['macro_f1']:.4f}\")\n",
    "print(f\"Weighted F1: {results['VGG16']['weighted_f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b69bd3",
   "metadata": {},
   "source": [
    "## 7. Comparative Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b6af7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison table\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': ['VGG16 (Mission 6)', 'PanCAN-ResNet101', 'PanCAN-ConvNeXt'],\n",
    "    'Accuracy': [\n",
    "        results['VGG16']['accuracy'],\n",
    "        results['PanCAN-ResNet101']['accuracy'],\n",
    "        results['PanCAN-ConvNeXt']['accuracy']\n",
    "    ],\n",
    "    'Macro F1': [\n",
    "        results['VGG16']['macro_f1'],\n",
    "        results['PanCAN-ResNet101']['macro_f1'],\n",
    "        results['PanCAN-ConvNeXt']['macro_f1']\n",
    "    ],\n",
    "    'Weighted F1': [\n",
    "        results['VGG16']['weighted_f1'],\n",
    "        results['PanCAN-ResNet101']['weighted_f1'],\n",
    "        results['PanCAN-ConvNeXt']['weighted_f1']\n",
    "    ],\n",
    "    'Cohen Kappa': [\n",
    "        results['VGG16']['cohen_kappa'],\n",
    "        results['PanCAN-ResNet101']['cohen_kappa'],\n",
    "        results['PanCAN-ConvNeXt']['cohen_kappa']\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL COMPARISON SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(comparison_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e135641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize comparison\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    subplot_titles=['Accuracy & F1 Comparison', 'Per-Class F1 Score']\n",
    ")\n",
    "\n",
    "# Bar chart for main metrics\n",
    "metrics_to_plot = ['Accuracy', 'Macro F1', 'Weighted F1']\n",
    "colors = ['#636EFA', '#EF553B', '#00CC96']\n",
    "\n",
    "for i, model in enumerate(['VGG16 (Mission 6)', 'PanCAN-ResNet101', 'PanCAN-ConvNeXt']):\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            name=model,\n",
    "            x=metrics_to_plot,\n",
    "            y=[comparison_df[comparison_df['Model']==model][m].values[0] for m in metrics_to_plot],\n",
    "            marker_color=colors[i]\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "\n",
    "# Per-class F1\n",
    "for i, (model_name, result) in enumerate([('VGG16', results['VGG16']),\n",
    "                                           ('PanCAN-R101', results['PanCAN-ResNet101']),\n",
    "                                           ('PanCAN-CvT', results['PanCAN-ConvNeXt'])]):\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            name=model_name,\n",
    "            x=class_names,\n",
    "            y=result['per_class_f1'],\n",
    "            marker_color=colors[i],\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Model Comparison: PanCAN vs VGG16',\n",
    "    barmode='group',\n",
    "    height=500\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4542881d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrices\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "models_data = [\n",
    "    ('VGG16', labels_vgg16, preds_vgg16),\n",
    "    ('PanCAN-ResNet101', labels_r101, preds_r101),\n",
    "    ('PanCAN-ConvNeXt', labels_cvt, preds_cvt)\n",
    "]\n",
    "\n",
    "for ax, (name, y_true, y_pred) in zip(axes, models_data):\n",
    "    cm = confusion_matrix(y_true, y_pred, normalize='true')\n",
    "    sns.heatmap(\n",
    "        cm, annot=True, fmt='.2f', cmap='Blues',\n",
    "        xticklabels=class_names, yticklabels=class_names,\n",
    "        ax=ax\n",
    "    )\n",
    "    ax.set_title(f'{name}\\nNormalized Confusion Matrix')\n",
    "    ax.set_ylabel('True Label')\n",
    "    ax.set_xlabel('Predicted Label')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(CONFIG['reports_path'] / 'figures' / 'confusion_matrices.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a32044",
   "metadata": {},
   "source": [
    "## 8. Feature Importance Analysis (PanCAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63fb552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize feature importance analyzer\n",
    "analyzer = FeatureImportanceAnalyzer(pancan_resnet101, device)\n",
    "\n",
    "# Get scale importance weights\n",
    "scale_weights = pancan_resnet101.cross_scale.scale_weights\n",
    "scale_weights_normalized = torch.softmax(scale_weights, dim=0).detach().cpu().numpy()\n",
    "\n",
    "print(\"\\nScale Importance Weights:\")\n",
    "for i, w in enumerate(scale_weights_normalized):\n",
    "    print(f\"  Scale {i+1}: {w:.4f} ({w*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdc4e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize scale importance\n",
    "fig = px.bar(\n",
    "    x=[f'Scale {i+1}' for i in range(4)],\n",
    "    y=scale_weights_normalized,\n",
    "    title='PanCAN Scale Importance Weights (Learned)',\n",
    "    labels={'x': 'Feature Scale', 'y': 'Weight'},\n",
    "    color=scale_weights_normalized,\n",
    "    color_continuous_scale='Viridis'\n",
    ")\n",
    "fig.update_layout(showlegend=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e6a2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize attention maps for sample images\n",
    "sample_batch = next(iter(test_loader))\n",
    "sample_images = sample_batch['pixel_values'][:4].to(device)\n",
    "sample_labels = sample_batch['labels'][:4]\n",
    "\n",
    "# Get attention maps\n",
    "with torch.no_grad():\n",
    "    output_dict = pancan_resnet101(sample_images, return_features=True)\n",
    "\n",
    "print(f\"\\nSample predictions:\")\n",
    "preds = output_dict['logits'].argmax(dim=-1)\n",
    "for i in range(4):\n",
    "    print(f\"  Image {i+1}: True={class_names[sample_labels[i]]}, Pred={class_names[preds[i]]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f963e07d",
   "metadata": {},
   "source": [
    "## 9. Training History Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcfec64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    subplot_titles=[\n",
    "        'PanCAN-ResNet101 Loss', 'PanCAN-ResNet101 Accuracy',\n",
    "        'PanCAN-ConvNeXt Loss', 'PanCAN-ConvNeXt Accuracy'\n",
    "    ]\n",
    ")\n",
    "\n",
    "# ResNet101\n",
    "epochs = range(1, len(history_resnet101['train_loss']) + 1)\n",
    "fig.add_trace(go.Scatter(x=list(epochs), y=history_resnet101['train_loss'], name='Train Loss', line=dict(color='blue')), row=1, col=1)\n",
    "fig.add_trace(go.Scatter(x=list(epochs), y=history_resnet101['val_loss'], name='Val Loss', line=dict(color='red', dash='dash')), row=1, col=1)\n",
    "fig.add_trace(go.Scatter(x=list(epochs), y=history_resnet101['train_acc'], name='Train Acc', line=dict(color='blue')), row=1, col=2)\n",
    "fig.add_trace(go.Scatter(x=list(epochs), y=history_resnet101['val_acc'], name='Val Acc', line=dict(color='red', dash='dash')), row=1, col=2)\n",
    "\n",
    "# ConvNeXt\n",
    "epochs_cvt = range(1, len(history_convnext['train_loss']) + 1)\n",
    "fig.add_trace(go.Scatter(x=list(epochs_cvt), y=history_convnext['train_loss'], name='Train Loss', line=dict(color='green'), showlegend=False), row=2, col=1)\n",
    "fig.add_trace(go.Scatter(x=list(epochs_cvt), y=history_convnext['val_loss'], name='Val Loss', line=dict(color='orange', dash='dash'), showlegend=False), row=2, col=1)\n",
    "fig.add_trace(go.Scatter(x=list(epochs_cvt), y=history_convnext['train_acc'], name='Train Acc', line=dict(color='green'), showlegend=False), row=2, col=2)\n",
    "fig.add_trace(go.Scatter(x=list(epochs_cvt), y=history_convnext['val_acc'], name='Val Acc', line=dict(color='orange', dash='dash'), showlegend=False), row=2, col=2)\n",
    "\n",
    "fig.update_layout(title='Training History', height=600)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ac7fb9",
   "metadata": {},
   "source": [
    "## 10. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7459d1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save comparison results\n",
    "comparison_df.to_csv(CONFIG['reports_path'] / 'model_comparison_results.csv', index=False)\n",
    "\n",
    "# Save detailed results\n",
    "import json\n",
    "with open(CONFIG['reports_path'] / 'detailed_results.json', 'w') as f:\n",
    "    # Convert numpy arrays to lists for JSON serialization\n",
    "    results_serializable = {}\n",
    "    for model, metrics in results.items():\n",
    "        results_serializable[model] = {\n",
    "            k: v if not isinstance(v, np.ndarray) else v.tolist()\n",
    "            for k, v in metrics.items()\n",
    "        }\n",
    "    json.dump(results_serializable, f, indent=2)\n",
    "\n",
    "print(\"\\nResults saved to:\")\n",
    "print(f\"  - {CONFIG['reports_path'] / 'model_comparison_results.csv'}\")\n",
    "print(f\"  - {CONFIG['reports_path'] / 'detailed_results.json'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5de1cdd",
   "metadata": {},
   "source": [
    "## 11. Conclusion\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "1. **Performance**: PanCAN with [best backbone] achieves **X%** improvement in Macro F1 over VGG16 baseline\n",
    "\n",
    "2. **Architecture Benefits**:\n",
    "   - Multi-order random walks capture global context\n",
    "   - Cross-scale aggregation leverages hierarchical features\n",
    "   - Fewer parameters while maintaining/improving performance\n",
    "\n",
    "3. **Interpretability**:\n",
    "   - Scale attention weights provide insights into feature importance\n",
    "   - Compatible with Grad-CAM for spatial localization\n",
    "\n",
    "### Recommendations\n",
    "\n",
    "- PanCAN is suitable for production deployment with proper optimization\n",
    "- ConvNeXt backbone offers best efficiency-performance trade-off\n",
    "- Further improvements possible with larger datasets and ensemble methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973c8a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"POC COMPLETE - Mission 8\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nBest Model: PanCAN-{['ResNet101', 'ConvNeXt'][np.argmax([results['PanCAN-ResNet101']['macro_f1'], results['PanCAN-ConvNeXt']['macro_f1']])]}\")\n",
    "print(f\"Best Macro F1: {max(results['PanCAN-ResNet101']['macro_f1'], results['PanCAN-ConvNeXt']['macro_f1']):.4f}\")\n",
    "print(f\"Improvement over VGG16: {(max(results['PanCAN-ResNet101']['macro_f1'], results['PanCAN-ConvNeXt']['macro_f1']) - results['VGG16']['macro_f1'])*100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
